%%
prepareData;

% train the model using the normalized data
%% gpudevice
try
    g = gpuDevice;
    catch Me;
        NoGPU = Me.cause;
end
%% initialise training option parameters
numFeatures = size(X_Train_n{1},1);
numHiddenUnits = 300;
numResponses = 1;
sequenceLength = 600;
fsIndex = 7;
maxSequenceLength = 2879;
useFeatureSelection = false;
allFeatures = 1:numFeatures;
% Network size parameters
% sizeFactor - a scalar multiple that increases the width of the LSTM
% layer. Subsequent layers have progressively smaller widths
widthFactor = 8;
% training Parameters
gradientThreshold = 4;
gradientDecayFactor = 0.9;
initialLearnRate = 0.0002;
learnRateDropFactor = 0.75;
learnRateDropPeriod = 2;
maxEpochs = 20;
miniBatchSize = 4;
validationPeriod = 20;
validationPatience = 10;
%%

size(X_Train_n)
size(Y_Train_n)
size(X_Test_n)
size(Y_Test_n)
%% 
%validationData = cellfun(@transpose,Y_Test_n,'UniformOutput',0);
%% Parametrise models and test their performance with different initializers
layersGlorot = [... 
    sequenceInputLayer(numFeatures,'Name','InputLayer1'),...
    lstmLayer(numHiddenUnits*widthFactor,'OutputMode','sequence','InputWeightsInitializer','Glorot','Name','LSTM_Layer1'),...
    fullyConnectedLayer(numHiddenUnits*widthFactor/2,'Name','FC_Layer1'),...
    lstmLayer(numHiddenUnits*widthFactor/2,'OutputMode','sequence','InputWeightsInitializer','Glorot','Name','LSTM_Layer2'),... 
    fullyConnectedLayer(numHiddenUnits*widthFactor/4,'Name','FC_Layer2'),...
    lstmLayer(numHiddenUnits*widthFactor/4,'OutputMode','sequence','InputWeightsInitializer','Glorot','Name','LSTM_Layer3'),... 
    fullyConnectedLayer(numHiddenUnits,'Name','FC_Layer3'),...
    lstmLayer(numHiddenUnits,'OutputMode','sequence','InputWeightsInitializer','Glorot','Name','LSTM_Layer4'),... 
    fullyConnectedLayer(numResponses,'name','FC_Layer_FINAL'),...
    regressionLayer('Name','RegressionLayer'),...
    ];
   
layersHe = [... 
    sequenceInputLayer(numFeatures,'Name','InputLayer1'),...
    lstmLayer(numHiddenUnits*widthFactor,'OutputMode','sequence','InputWeightsInitializer','He','Name','LSTM_Layer1'),...
    fullyConnectedLayer(numHiddenUnits*widthFactor/2,'Name','FC_Layer1'),...
    lstmLayer(numHiddenUnits*widthFactor/2,'OutputMode','sequence','InputWeightsInitializer','He','Name','LSTM_Layer2'),... 
    fullyConnectedLayer(numHiddenUnits*widthFactor/4,'Name','FC_Layer2'),...
    lstmLayer(numHiddenUnits*widthFactor/4,'OutputMode','sequence','InputWeightsInitializer','He','Name','LSTM_Layer3'),... 
    fullyConnectedLayer(numHiddenUnits,'Name','FC_Layer3'),...
    lstmLayer(numHiddenUnits,'OutputMode','sequence','InputWeightsInitializer','He','Name','LSTM_Layer4'),...
    fullyConnectedLayer(numResponses,'name','FC_Layer_FINAL'),...    
    regressionLayer('Name','RegressionLayer'),...
    ];
   
layersNN = [... 
    sequenceInputLayer(numFeatures,'Name','InputLayer1'),...
    lstmLayer(numHiddenUnits*widthFactor,'OutputMode','sequence','InputWeightsInitializer','narrow-normal','Name','LSTM_Layer1'),...
    fullyConnectedLayer(numHiddenUnits*widthFactor/2,'Name','FC_Layer1'),...
    lstmLayer(numHiddenUnits*widthFactor/2,'OutputMode','sequence','InputWeightsInitializer','narrow-normal','Name','LSTM_Layer2'),... 
    fullyConnectedLayer(numHiddenUnits*widthFactor/4,'Name','FC_Layer2'),...
    lstmLayer(numHiddenUnits*widthFactor/4,'OutputMode','sequence','InputWeightsInitializer','narrow-normal','Name','LSTM_Layer3'),... 
    fullyConnectedLayer(numHiddenUnits,'Name','FC_Layer3'),...
    lstmLayer(numHiddenUnits,'OutputMode','sequence','InputWeightsInitializer','narrow-normal','Name','Bi_LSTM_Layer4'),...
    fullyConnectedLayer(numResponses,'Name','FC_Layer_FINAL'),...
    regressionLayer('Name','RegressionLayer'),...
    ];

modelSummary = [...
    {'Trained with Glorot Input Weight Initialization for all LSTM layers'};
    {'Trained with He Input Weight Initialization for all LSTM layers'};
    {'Trained with NN Input Weight Initialization for all LSTM layers'};
];
%lnet = layerGraph(layers);
% 
% options1 = trainingOptions('sgdm', ...
%     'MaxEpochs',maxEpochs, ...
%     'SequenceLength','Shortest', ...
%     'InitialLearnRate',0.000125, ...
%     'LearnRateSchedule','piecewise', ...
%     'Verbose',1, ...
%     "ValidationData",[{XTest_cell};{YTest_cell}],...
%     "ValidationFrequency",validationPeriod,...
%     'Plots','training-progress');

t_options = trainingOptions('adam', ...
'Shuffle','never',...
'ExecutionEnvironment','auto',...    
'MaxEpochs',maxEpochs, ...
    'SequenceLength','Shortest', ...
    'MiniBatchSize',miniBatchSize,...
    'GradientDecayFactor',gradientDecayFactor,...
    'GradientThreshold',gradientThreshold, ...
    'InitialLearnRate',initialLearnRate, ...
    'LearnRateSchedule','piecewise', ...
    'LearnRateDropPeriod',learnRateDropPeriod, ...
    'LearnRateDropFactor',learnRateDropFactor, ...
    'Verbose',1, ...
    "ValidationData",[{X_Test_n};{Y_Test_n}],...
    "ValidationFrequency",validationPeriod,...
    'ValidationPatience',validationPatience,...
    'Plots','training-progress')

% t_options_sgdm = trainingOptions('sgdm', ...
% 'ExecutionEnvironment','gpu',...    
% 'MaxEpochs',maxEpochs, ...
%     'SequenceLength','Shortest', ...
%     'MiniBatchSize',miniBatchSize,...
%     'GradientThreshold',gradientThreshold, ...
%     'InitialLearnRate',initialLearnRate*10, ...
%     'LearnRateSchedule','piecewise', ...
%     'LearnRateDropPeriod',learnRateDropPeriod, ...
%     'LearnRateDropFactor',learnRateDropFactor, ...
%     'Verbose',1, ...
%     "ValidationData",[{X_Test_n};{Y_Test_n}],...
%     "ValidationFrequency",validationPeriod,...
%     'Plots','training-progress');

%% train the models
numFeatures
%
% 
% try
%     nnet.internal.cnngpu.reluForward(1);
% catch ME
% end
% reset(g);
tic;
[netGlorot, infoGlorot] = trainNetwork(X_Train_n,Y_Train_n,layersGlorot,t_options);
tt_Glorot = toc;
% try
%     nnet.internal.cnngpu.reluForward(1);
% catch ME
% end
% reset(g);
tic;
[netHe, infoHe] = trainNetwork(X_Train_n,Y_Train_n,layersHe,t_options);
tt_He = toc;

% try
%     nnet.internal.cnngpu.reluForward(1);
% catch ME
% end
% reset(g);

tic;
[netNN, infoNN] = trainNetwork(X_Train_n,Y_Train_n,layersNN,t_options);
tt_NN = toc;
%%
% predict model outputs
YPredGlorot = predict(netGlorot,X_Test_n,'MiniBatchSize',1);
YPredHe = predict(netHe,X_Test_n,'MiniBatchSize',1);
YPredNN = predict(netNN,X_Test_n,'MiniBatchSize',1);

%% normalize the outputs w.r.t. the min and max of Y_Train_u
accThreshold = 0.10*mode(Y_Train_u);

% YPredHe_n = cellfun(@normalize,YPredHe,'range',[ymin,ymax]);
% YPredNN_n = cellfun(@normalize,YPredNN,'range',[ymin,ymax]);
% [YPredGlorot_n, ~, ~, ~] = normalizeOutputRange(YPredGlorot,ymin,ymax);
% [YPredHe_n, ~, ~, ~] = normalizeOutputRange(YPredHe,ymin,ymax);
% [YPredNN_n, ~, ~, ~] = normalizeOutputRange(YPredNN,ymin,ymax);
% savedHere = Y_Test_n;
% Y_Test_n = Y_Test_n';
%% Return the predictions to the original scaling of the data by normalizing the predictions
%  within the min and max of the input testing data
%% 

%%
YMIN = repmat({ymin},1,12);
YMAX = repmat({ymax},1,12);
ydiff = repmat({ymax-ymin},1,12);

YPredGlorot_n = cellfun(@(A,B,C) (A(:)-B)./(C-B), YPredGlorot,YMIN',YMAX','UniformOutput',0);
YPredHe_n = cellfun(@(A,B,C) (A(:)-B)./(C-B), YPredHe,YMIN',YMAX','UniformOutput',0);
YPredNN_n = cellfun(@(A,B,C) (A(:)-B)./(C-B), YPredNN,YMIN',YMAX','UniformOutput',0);
%%
Y_Test_n  = cellfun(@(A,B,C) (A(:)-B)./(C-B), Y_Test_n,YMIN',YMAX','UniformOutput',0);
%Y_Test_n = cellfun(@transpose,Y_Test_n,'UniformOutput',0);
%%

% validationRMSE = [infoGlorot.ValidationRMSE;
%     infoHe.ValidationRMSE;
%     infoNN.ValidationRMSE;];
% 
% idx = all(isnan(validationRMSE));
% validationRMSE(:,idx) = [];
%%
for i = 1:numel(Y_Test_n)
    figure(i+5); clf reset;
%     foundIndexes = find(YTest_re.Index == si_test(i));
%     datetimes_i{i} = table2array(YTest_re(foundIndexes,2));
%     times_i{i} = table2array(YTest_re(foundIndexes,3));
%     dt_i{i} = (datetimes_i{i}.Year + datetimes_i{i}.Month + datetimes_i{i}.Day + (times_i{i}));
%     % if there are more timesteps than predictions:
%     % truncate the predictions at the correct timestep
%     if numel(dt_i{i}) > numel(YPredGlorot{i})
%         oldTimes = dt_i{i};
%         newTimes = oldTimes(1:numel(YPredGlorot{i}));
%         dt_i{i} = newTimes;
%     end
    % plot a timeseries based on the sequence indexes]
    predictions = [Y_Test_n{i},YPredGlorot_n{i},YPredHe_n{i},YPredNN_n{i}];
    timesteps = 1:numel(Y_Test_n{i})';
    plot(timesteps,predictions,'LineWidth',2);
    %ylim([0.375, 0.525]);
    legend(["Targets" "Glorot" "He" "Narrow Normal"],'Location','Best','FontSize',14);
    xlabel('Time Step','FontSize',16);
    ylabel('Z-axis displacement (normalised)','FontSize',16);
    titlestr = strcat("Predicted Outputs Exp no.",num2str(i));
    title(titlestr,'FontSize',16);
end
filename = ['training-details-',date(),'.mat'];
save(filename);