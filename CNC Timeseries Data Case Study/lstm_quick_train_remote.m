%%
set(0,'DefaultFigureWindowStyle','Docked');
% Prepare data according to a runtime script
prepareData;
% deployAutoencoder;
% train the model using the normalized data
%% gpudevice
g = gpuDevice;
%% initialise training option parameters
numFeatures = size(X_Train_n{1},1);
numHiddenUnits = 100;
numResponses = 1;
sequenceLength = 720;
fsIndex = 7;
maxSequenceLength = 2879;
useFeatureSelection = false;
allFeatures = 1:numFeatures;
% Network size parameters
% sizeFactor - a scalar multiple that increases the width of the LSTM
% layer. Subsequent layers have progressively smaller widths
widthFactor = 8;
% training Parameters
gradientThreshold = Inf;
%gradientDecayFactor = 0.5;
initialLearnRate = 0.0004;
learnRateDropFactor = 0.8;
learnRateDropPeriod = 5;
maxEpochs = 50;
miniBatchSize = 16;
validationPeriod = 20;
validationPatience = 10;
bl2f = 0.4;
%% Parametrise models and test their performance with different initializers
layersGlorot = [... 
    sequenceInputLayer(numFeatures,'Name','InputLayer1'),...
    lstmLayer(numHiddenUnits*widthFactor,'OutputMode','sequence',...
    'RecurrentWeightsInitializer','Glorot','InputWeightsInitializer','Glorot',...
    'Name','LSTM_Layer1'),...
    fullyConnectedLayer(numHiddenUnits*widthFactor/2,'Name','FC_Layer1'),...
    lstmLayer(numHiddenUnits*widthFactor/2,'OutputMode','sequence',...
    'RecurrentWeightsInitializer','Glorot','InputWeightsInitializer','Glorot',...
    'Name','LSTM_Layer2'),... 
    fullyConnectedLayer(numHiddenUnits*widthFactor/4,'Name','FC_Layer2'),...
    lstmLayer(numHiddenUnits*widthFactor/4,'OutputMode','sequence',...
    'RecurrentWeightsInitializer','Glorot','InputWeightsInitializer','Glorot',...
    'Name','LSTM_Layer3'),... 
    fullyConnectedLayer(numHiddenUnits,'Name','FC_Layer3'),...
    lstmLayer(numHiddenUnits,'OutputMode','sequence',...
    'RecurrentWeightsInitializer','Glorot','InputWeightsInitializer','Glorot',...
    'Name','LSTM_Layer4'),... 
    fullyConnectedLayer(numResponses,'name','FC_Layer_FINAL'),...
    regressionLayer('Name','RegressionLayer'),...
    ];

% numFeatures_AE = size(X_Train_AE{1},1);
% layersGlorot_AE = [... 
%     sequenceInputLayer(numFeatures_AE,'Name','InputLayer1'),...
%     lstmLayer(numHiddenUnits*widthFactor,'OutputMode','sequence','InputWeightsInitializer','Glorot','Name','LSTM_Layer1'),...
%     fullyConnectedLayer(numHiddenUnits*widthFactor/2,'Name','FC_Layer1'),...
%     lstmLayer(numHiddenUnits*widthFactor/2,'OutputMode','sequence','InputWeightsInitializer','Glorot','Name','LSTM_Layer2'),... 
%     fullyConnectedLayer(numHiddenUnits*widthFactor/4,'Name','FC_Layer2'),...
%     lstmLayer(numHiddenUnits*widthFactor/4,'OutputMode','sequence','InputWeightsInitializer','Glorot','Name','LSTM_Layer3'),... 
%     fullyConnectedLayer(numHiddenUnits,'Name','FC_Layer3'),...
%     lstmLayer(numHiddenUnits,'OutputMode','sequence','InputWeightsInitializer','Glorot','Name','LSTM_Layer4'),... 
%     fullyConnectedLayer(numResponses,'name','FC_Layer_FINAL'),...
%     regressionLayer('Name','RegressionLayer'),...
%     ];

% layersHe = [... 
%     sequenceInputLayer(numFeatures,'Name','InputLayer1'),...
%     lstmLayer(numHiddenUnits*widthFactor,'OutputMode','sequence','InputWeightsInitializer','He','Name','LSTM_Layer1'),...
%     fullyConnectedLayer(numHiddenUnits*widthFactor/2,'Name','FC_Layer1'),...
%     lstmLayer(numHiddenUnits*widthFactor/2,'OutputMode','sequence','InputWeightsInitializer','He','Name','LSTM_Layer2'),... 
%     fullyConnectedLayer(numHiddenUnits*widthFactor/4,'Name','FC_Layer2'),...
%     lstmLayer(numHiddenUnits*widthFactor/4,'OutputMode','sequence','InputWeightsInitializer','He','Name','LSTM_Layer3'),... 
%     fullyConnectedLayer(numHiddenUnits,'Name','FC_Layer3'),...
%     lstmLayer(numHiddenUnits,'OutputMode','sequence','InputWeightsInitializer','He','Name','LSTM_Layer4'),...
%     fullyConnectedLayer(numResponses,'name','FC_Layer_FINAL'),...    
%     regressionLayer('Name','RegressionLayer'),...
%     ];
%    
% layersNN = [... 
%     sequenceInputLayer(numFeatures,'Name','InputLayer1'),...
%     lstmLayer(numHiddenUnits*widthFactor,'OutputMode','sequence','InputWeightsInitializer','narrow-normal','Name','LSTM_Layer1'),...
%     fullyConnectedLayer(numHiddenUnits*widthFactor/2,'Name','FC_Layer1'),...
%     lstmLayer(numHiddenUnits*widthFactor/2,'OutputMode','sequence','InputWeightsInitializer','narrow-normal','Name','LSTM_Layer2'),... 
%     fullyConnectedLayer(numHiddenUnits*widthFactor/4,'Name','FC_Layer2'),...
%     lstmLayer(numHiddenUnits*widthFactor/4,'OutputMode','sequence','InputWeightsInitializer','narrow-normal','Name','LSTM_Layer3'),... 
%     fullyConnectedLayer(numHiddenUnits,'Name','FC_Layer3'),...
%     lstmLayer(numHiddenUnits,'OutputMode','sequence','InputWeightsInitializer','narrow-normal','Name','Bi_LSTM_Layer4'),...
%     fullyConnectedLayer(numResponses,'Name','FC_Layer_FINAL'),...
%     regressionLayer('Name','RegressionLayer'),...
%     ];

modelSummary = [...
    {'Trained with Glorot Input and Recurrent Weight Initialization for all LSTM layers; smaller mini-batch'};   
];
%{'Autoencoder-Augmented, Trained with Glorot Input Weight Initialization for all LSTM layers'};
xtrain_concat = horzcat(X_Train_n{:});
xmode = mode(xtrain_concat,'all');
spv = xmode;
t_options = trainingOptions('adam', ...
'Shuffle','never',...
'ExecutionEnvironment','gpu',...    
'MaxEpochs',maxEpochs, ...
    'SequenceLength',sequenceLength, ...
    'SequencePaddingValue',spv,...
    'MiniBatchSize',miniBatchSize,...
    'GradientThreshold',gradientThreshold, ...
    'InitialLearnRate',initialLearnRate, ...
    'LearnRateSchedule','piecewise', ...
    'LearnRateDropPeriod',learnRateDropPeriod, ...
    'LearnRateDropFactor',learnRateDropFactor, ...
    'Verbose',1, ...
    "ValidationData",[{X_Test_n};{Y_Test_n}],...
    "ValidationFrequency",validationPeriod,...
    'ValidationPatience',validationPatience,...
    'Plots','training-progress')

% t_options_ae = trainingOptions('adam', ...
% 'Shuffle','never',...
% 'ExecutionEnvironment','gpu',...    
% 'MaxEpochs',maxEpochs, ...
%     'SequenceLength',sequenceLength, ...
%     'SequencePaddingValue',spv,...
%     'MiniBatchSize',miniBatchSize,...
%     'GradientThreshold',gradientThreshold, ...
%     'InitialLearnRate',initialLearnRate, ...
%     'LearnRateSchedule','piecewise', ...
%     'LearnRateDropPeriod',learnRateDropPeriod, ...
%     'LearnRateDropFactor',learnRateDropFactor, ...
%     'Verbose',1, ...
%     "ValidationData",[{X_Test_AE};{Y_Test_n}],...
%     "ValidationFrequency",validationPeriod,...
%     'ValidationPatience',validationPatience,...
%     'Plots','training-progress')
%'GradientDecayFactor',gradientDecayFactor,...
%% train the models

try
    nnet.internal.cnngpu.reluForward(1);
catch ME
end
reset(g);
tic;
[netGlorot, infoGlorot] = trainNetwork(X_Train_n,Y_Train_n,layersGlorot,t_options);
%
tt_Glorot = toc;
% try
%     nnet.internal.cnngpu.reluForward(1);
% catch ME
% end
% reset(g);
% tic;
% [netGlorotAE, infoGlorotAE] = trainNetwork(X_Train_AE,Y_Train_n,layersGlorot_AE,t_options_ae);
% tt_Glorot_AE = toc;
%
% try
%     nnet.internal.cnngpu.reluForward(1);
% catch ME
% end
% reset(g);
% tic;
% [netHe, infoHe] = trainNetwork(X_Train_n,Y_Train_n,layersHe,t_options);
% tt_He = toc;
% 
% try
%     nnet.internal.cnngpu.reluForward(1);
% catch ME
% end
% reset(g);
% 
% tic;
% [netNN, infoNN] = trainNetwork(X_Train_n,Y_Train_n,layersNN,t_options);
% tt_NN = toc;
dockfig('all');
%%
% predict model outputs
YPredGlorot = predict(netGlorot,X_Test_n,'MiniBatchSize',1);
% YPredGlorot_AE = predict(netGlorotAE,X_Test_AE,'MiniBatchSize',1);
%YPredNN = predict(netNN,X_Test_n,'MiniBatchSize',1);
%% Return Y_Test_n to the original space of the predictions by normalizing it between YMIN and YMAX
YMIN = repmat({ymin},1,12);
YMAX = repmat({ymax},1,12);
Y_Test_n  = cellfun(@(A,B,C) (A(:)-B)./(C-B), Y_Test_n,YMIN',YMAX','UniformOutput',0);
%Y_Test_n = cellfun(@transpose,Y_Test_n,'UniformOutput',0);
%% Set the accuracy threshold of the 
accThreshold = 0.10*mode(Y_Train_u);
%% Return the predictions to the original scaling of the data by normalizing the predictions
%  within the min and max of the testing targets
YPredGlorot_n = cellfun(@(A,B,C) (A(:)-B)./(C-B), YPredGlorot,YMIN',YMAX','UniformOutput',0);
%YPredGlorot_AE_n = cellfun(@(A,B,C) (A(:)-B)./(C-B), YPredGlorot_AE,YMIN',YMAX','UniformOutput',0);
%YPredNN_n = cellfun(@(A,B,C) (A(:)-B)./(C-B), YPredNN,YMIN',YMAX','UniformOutput',0);
%%
[pa_Glorot,RMSE_Glorot]=benchmarkModel(YPredGlorot_n',Y_Test_n,accThreshold);
%[pa_Glorot_AE,RMSE_Glorot_AE]=benchmarkModel(YPredGlorot_AE_n',Y_Test_n,accThreshold);
% [pa_He,RMSE_He]=benchmarkModel(YPredHe_n,Y_Test_n,accThreshold);
% [pa_NN,RMSE_NN]=benchmarkModel(YPredNN_n,Y_Test_n,accThreshold);
%%
for i = 1:numel(Y_Test_n)
    figure(i+5); clf reset;
%     foundIndexes = find(YTest_re.Index == si_test(i));
%     datetimes_i{i} = table2array(YTest_re(foundIndexes,2));
%     times_i{i} = table2array(YTest_re(foundIndexes,3));
%     dt_i{i} = (datetimes_i{i}.Year + datetimes_i{i}.Month + datetimes_i{i}.Day + (times_i{i}));
%     % if there are more timesteps than predictions:
%     % truncate the predictions at the correct timestep
%     if numel(dt_i{i}) > numel(YPredGlorot{i})
%         oldTimes = dt_i{i};
%         newTimes = oldTimes(1:numel(YPredGlorot{i}));
%         dt_i{i} = newTimes;
%     end
    % plot a timeseries based on the sequence indexes]
    tgts = Y_Test_n{i};
    %predictions = [tgts,YPredGlorot_n{i},YPredGlorot_AE_n{i}];
    predictions1 = [tgts,YPredGlorot_n{i}];
    timesteps = 1:numel(Y_Test_n{i})';
    plot(timesteps,predictions1,'LineWidth',2);
    %ylim([0.375, 0.525]);
    legend(["Targets" "Predictions (Reduced Width)"],'Location','Best','FontSize',14);
    xlabel('Time Step','FontSize',16);
    ylabel('Z-axis displacement (normalised)','FontSize',16);
    titlestr = strcat("Predicted Outputs Exp no.",num2str(i));
    title(titlestr,'FontSize',16);
end
%% Save results into a struct (todo)
filename = ['training-details-',date(),'-desc-04-medbl2f','.mat'];
save(filename,'t_options','layersGlorot','Y_Test_n','YPredGlorot_n','modelSummary','infoGlorot');